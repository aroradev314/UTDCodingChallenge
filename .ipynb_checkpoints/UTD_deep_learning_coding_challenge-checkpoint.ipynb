{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ade97895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torchsummary\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7c266aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "619e54d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vehicle(Dataset):\n",
    "    def __init__(self, vehicles, labels):\n",
    "        self.vehicles = vehicles\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.vehicles)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.vehicles[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69527c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.getcwd()\n",
    "images_directory = os.path.join(root, \"vehicle_classification\")\n",
    "images = []\n",
    "labels = []\n",
    "current_label = 0\n",
    "for label in os.listdir(images_directory): #loop over every class\n",
    "    if not label.startswith('.'): # skip hidden directories\n",
    "        label_directory = os.path.join(images_directory, label)\n",
    "        for pic in os.listdir(label_directory): \n",
    "            image = Image.open(os.path.join(label_directory, pic))\n",
    "            image_array = np.array(image)\n",
    "            image_array = np.transpose(image_array, (2, 0, 1)) #make channels-first, as this is what PyTorch supports\n",
    "            images.append(image_array)\n",
    "            labels.append(current_label)\n",
    "        current_label += 1\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "classes = np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1d28753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 26378 images in the dataset\n",
      "Each image has dimensions 64x64\n",
      "The total number of classes is 8\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(classes)\n",
    "image_height, image_length = len(images[0][0]), len(images[0][0][0])\n",
    "print(f\"There are {len(images)} images in the dataset\")\n",
    "print(f\"Each image has dimensions {image_length}x{image_height}\")\n",
    "print(f\"The total number of classes is {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a16434b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "images, labels, test_size=0.20, random_state=42) #split into random train and test sets\n",
    "X_train = torch.tensor(X_train).to(device)\n",
    "X_test = torch.tensor(X_test).to(device)\n",
    "y_train = torch.tensor(y_train).type(torch.LongTensor).to(device)\n",
    "y_test = torch.tensor(y_test).type(torch.LongTensor).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c99d3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "kernel_size = 3\n",
    "train_dataloader = DataLoader(Vehicle(X_train, y_train), batch_size=batch_size)\n",
    "test_dataloader = DataLoader(Vehicle(X_test, y_test), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "172b3cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        modules = []\n",
    "        modules.append(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=kernel_size, padding='same')) \n",
    "        modules.append(\n",
    "            nn.Dropout(0.5)) # some inputs are randomly dropped\n",
    "        modules.append(\n",
    "            nn.ReLU())\n",
    "        modules.append(\n",
    "            nn.MaxPool2d(kernel_size=kernel_size * 2))\n",
    "        \n",
    "        modules.append(\n",
    "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=kernel_size, padding='same')) \n",
    "        modules.append(\n",
    "            nn.Dropout(0.5)) # some inputs are randomly dropped\n",
    "        modules.append(\n",
    "            nn.ReLU())\n",
    "        modules.append(\n",
    "            nn.MaxPool2d(kernel_size=kernel_size * 2)) \n",
    "        \n",
    "        modules.append(nn.Flatten())\n",
    "        modules.append(nn.Linear(16, 256)) # dense layer with 256 neurons \n",
    "        modules.append(nn.ReLU())\n",
    "        modules.append(\n",
    "            nn.Linear(256, num_classes))\n",
    "        modules.append(\n",
    "            nn.LogSoftmax(dim=1))\n",
    "    \n",
    "        self.network = nn.Sequential(*modules) # unpack the modules\n",
    "    \n",
    "    # Returns the summary of the model architecture given an input size\n",
    "    def summary(self): \n",
    "        return torchsummary.summary(self, input_size=(3, image_height, image_length))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        prob = self.network(x)\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2317d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total_loss = 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = X.type(torch.FloatTensor)\n",
    "        # Compute prediction error\n",
    "        pred = model(X).to(device)\n",
    "        loss = loss_fn(pred, y).to(device)\n",
    "        \n",
    "        _, predicted = torch.max(pred.data, 1)\n",
    "        correct += (predicted == y).sum().item()\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "            \n",
    "            \n",
    "    accuracy = correct / size\n",
    "    average_loss = total_loss / num_batches # get average loss by dividing sum of losses by total batches\n",
    "    train_loss.append(average_loss)\n",
    "    train_acc.append(accuracy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb9bec7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn, \n",
    "         loss_graph, accuracy_graph, train_loss, test_loss, train_acc, test_acc, cur_epoch):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.type(torch.FloatTensor)\n",
    "            pred = model(X).to(device) # compute the model prediction\n",
    "            \n",
    "            # the predicted class is the one with the highest probability \n",
    "            # in the output distribution\n",
    "            _, predicted = torch.max(pred.data, 1)\n",
    "            correct += (predicted == y).sum().item()\n",
    "            \n",
    "            total_loss += loss_fn(pred, y).to(device).item()\n",
    "            \n",
    "    accuracy = correct / size\n",
    "    average_loss = total_loss / num_batches # get average loss by dividing sum of losses by total batches\n",
    "    test_loss.append(average_loss)\n",
    "    test_acc.append(accuracy)\n",
    "    \n",
    "    epochs = np.arange(1, cur_epoch + 1) # create x-axis values\n",
    "    loss_graph.plot(epochs, train_loss, label=\"Train\")\n",
    "    loss_graph.plot(epochs, test_loss, label=\"Test\")\n",
    "    accuracy_graph.plot(epochs, train_acc, label=\"Train\")\n",
    "    accuracy_graph.plot(epochs, test_acc, label=\"Test\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "364f862e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 64, 64]             448\n",
      "           Dropout-2           [-1, 16, 64, 64]               0\n",
      "              ReLU-3           [-1, 16, 64, 64]               0\n",
      "         MaxPool2d-4           [-1, 16, 10, 10]               0\n",
      "            Conv2d-5           [-1, 16, 10, 10]           2,320\n",
      "           Dropout-6           [-1, 16, 10, 10]               0\n",
      "              ReLU-7           [-1, 16, 10, 10]               0\n",
      "         MaxPool2d-8             [-1, 16, 1, 1]               0\n",
      "           Flatten-9                   [-1, 16]               0\n",
      "           Linear-10                  [-1, 256]           4,352\n",
      "             ReLU-11                  [-1, 256]               0\n",
      "           Linear-12                    [-1, 8]           2,056\n",
      "       LogSoftmax-13                    [-1, 8]               0\n",
      "================================================================\n",
      "Total params: 9,176\n",
      "Trainable params: 9,176\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 1.55\n",
      "Params size (MB): 0.04\n",
      "Estimated Total Size (MB): 1.63\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19bbac64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_axes(num_epochs):\n",
    "    fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2) # create 2 different subplots to graph the loss and the accuracy\n",
    "    ax1.set_xlim(0, num_epochs)\n",
    "    ax1.set_ylim(0, 1)\n",
    "    ax2.set_xlim(0, num_epochs)\n",
    "    ax2.set_ylim(0, 1)\n",
    "\n",
    "    ax1.set_title(\"Model Loss vs. Epoch\")\n",
    "    ax2.set_title(\"Model Accuracy vs. Epoch\")\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax2.set_xlabel(\"Epoch\")\n",
    "    ax2.set_ylabel(\"Accuracy\")\n",
    "    return ax1, ax2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "20b61428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n",
      "-------------------------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 310.14 MB, other allocations: 8.77 GB, max allowed: 9.07 GB). Tried to allocate 2.00 KB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [35]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     test(test_dataloader, model, loss_fn, loss_ax, accuracy_ax, train_loss, test_loss, train_acc, test_acc, t \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      8\u001b[0m X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mFloatTensor)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Compute prediction error\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(pred, y)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(pred\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 310.14 MB, other allocations: 8.77 GB, max allowed: 9.07 GB). Tried to allocate 2.00 KB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "loss_fn = nn.NLLLoss().to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "train_loss, test_loss, train_acc, test_acc = [], [], [], []\n",
    "\n",
    "epochs = 100\n",
    "(loss_ax, accuracy_ax) = create_axes(epochs)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn, loss_ax, accuracy_ax, train_loss, test_loss, train_acc, test_acc, t + 1)\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38941ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Vehicle Classification",
   "language": "python",
   "name": "vehicle_classification"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
